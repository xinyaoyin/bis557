---
title: "Homework-3"
author: "Xinyao Yin"
date: "11/09/2018"

output:
  html_document:
    self_contained: yes
    toc: true
---
<!--
%\VignetteEngine{knitr::rmarkdown}
%\VignetteIndexEntry{HW3 vignette}
-->

## Question 1 (Page 117.7)
Write a function kern_density and visually test how this performs for some hand constructed datasets and bandwidths

```{r}
#Create the Epanechnikov kernel function with bandwidth = 1
epan_kernel <-function(x,h=1){
  x <-x/h
  a <- as.numeric(abs(x) <= 1)
  value <- (3/4) * ( 1 - x^2 ) * a
  return(value)
}

#Create the kernel density function.
#x: training vector 
#x_new: test set
#h: bandwidth 
#return kernel density estimate 

h = 1
kern_density <- function(x, h, x_new){
  sapply(x_new, function(k){
    estimate <-mean(epan_kernel(k-x,h))/h
    return(estimate)
  })
  }

# create a list of bandwidth for testing 
h = c(0.01,0.1,0.5,1,2)

# hand construct a testing dataset 
set.seed(666)
x <- rnorm(2000, 0, 1)
x_new <- sort(rnorm(100, 0, 1))

# visually test the function with different bandwidth 
for (i in h){
  plot(x_new, kern_density(x,i,x_new), xlab = "x",ylab = "Kernel Density", main = paste("Kernel Density Estimates for bandwidth =", i),type="l",col="orange")  
}

```

From the plots we can see that as the bandwidth becomes larger, the kernel estimate becomes smoother. 


## Question 2 (Page 200.3)
```{r echo=FALSE, out.width='100%'}
# embbed pictures into r
knitr::include_graphics('/Users/graceyin/Desktop/bis557/data-raw/Question 3.jpeg')

```


## Question 3 (Page 200.4)

```{r echo=FALSE, out.width='100%'}
# embbed pictures into r
knitr::include_graphics('/Users/graceyin/Desktop/bis557/data-raw/Question 4.jpeg')
```

## Question 4 (Page 200.5)

```{r echo=FALSE, out.width='100%'}
# embbed pictures into r
knitr::include_graphics('/Users/graceyin/Desktop/bis557/data-raw/Question 5.jpeg')
```

## Question 5 (Page 200.6)

Check KKT conditions for glmnet
```{r}
#Check current KKT conditions for regression vector (reference to Textbook page 189)

# Args:
#     X: A numeric data matrix.
#     y: Response vector.
#     b: Current value of the regression vector.
#     lambda: The penalty term.
#
# Returns:
#     A logical vector indicating where the KKT conditions have
#     been violated by the variables that are currently zero.

casl_lenet_check_kkt <- function(X, y, b, lambda) {
  
  resids <- y - X %*% b 
  s <- apply(X, 2, function(xj) crossprod(xj, resids)) /
    lambda / nrow(X)
  # return a vector indicating where the KKT conditions have been
  # violated by the variables that are currently zero 
  (b == 0) & (abs(s) >=1)
}

```

Implement lasso_reg_with_screening function (set alpha to 1)
```{r}
#install.packages("glmnet")
library("glmnet")

#Check variables to see if they violate KKT conditions

# Args:
#     x:numeric values of a data matrix
#     y:response vector
#     
# Returns:
#     A logical vector indicating whether the KKT conditions have been violated
#     If KKT conditions are violated, return a vector that contains at least one TRUE
#     If KKT conditions are not violated, return a vector of FALSEs

lasso_reg_with_screening <- function(x, y){
  est <- cv.glmnet(x,y,alpha=1)
  lambda <- est$lambda.1se
  b <- est$glmnet.fit$beta[,est$lambda == lambda]
  print(b)
  casl_lenet_check_kkt(x, y, b, lambda)
}
``` 

Test on the Iris dataset 
```{r}
data("iris")
x <- scale(model.matrix(Sepal.Length ~. -1, iris))
y <- iris[,1]
lasso_reg_with_screening(x, y)
```

We get FALSE for all coefficient estimates. This indicates that no KKT conditions have been violated. 
